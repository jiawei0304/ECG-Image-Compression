{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b902f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from decimal import Decimal, getcontext\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f9133",
   "metadata": {},
   "source": [
    "Arithmetic Coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a8ea24-ed0f-4d78-b279-d3cdc08f504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "getcontext().prec = 100  # Increase precision\n",
    "\n",
    "def arithmetic_compress(data):\n",
    "    freq = {}\n",
    "    for symbol in data:\n",
    "        freq[symbol] = freq.get(symbol, 0) + 1\n",
    "    total = sum(freq.values())\n",
    "\n",
    "    low = {}\n",
    "    high = {}\n",
    "    cumulative = Decimal(0)\n",
    "    for symbol, count in sorted(freq.items()):\n",
    "        low[symbol] = cumulative\n",
    "        high[symbol] = cumulative + Decimal(count) / Decimal(total)\n",
    "        cumulative = high[symbol]\n",
    "\n",
    "    l = Decimal(0)\n",
    "    h = Decimal(1)\n",
    "    for symbol in data:\n",
    "        range_ = h - l\n",
    "        h = l + range_ * high[symbol]\n",
    "        l = l + range_ * low[symbol]\n",
    "\n",
    "    code = (l + h) / 2\n",
    "    return code, low, high\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9680a75",
   "metadata": {},
   "source": [
    "\n",
    "Convolutional Autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG_CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECG_CAE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        _, _, h, w = x.size()\n",
    "        decoded = decoded[:, :, :h, :w]\n",
    "        return encoded, decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b8d9f",
   "metadata": {},
   "source": [
    "transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((296, 1024)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "def get_dataloader(data_dir, batch_size=16, shuffle=True):\n",
    "    dataset = ImageFolder(data_dir, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881e23a",
   "metadata": {},
   "source": [
    "Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d7d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, device, num_epochs=10, lr=1e-3, save_path=\"ecg_cae.pth\"):\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for images, _ in dataloader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            _, outputs = model(images)\n",
    "            loss = criterion(outputs, images)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.6f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb5c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = []\n",
    "def process_folder(model, folder_path, device, output_folder=\"cae_arithmetirc\"):\n",
    "    model.eval()\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    total_original_size = 0\n",
    "    total_compressed_size = 0\n",
    "\n",
    "    for filename in image_files:\n",
    "        start_time = time.time()\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        resized = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoded, decoded = model(resized)\n",
    "\n",
    "        # Save reconstructed image\n",
    "        output_img = decoded.cpu().squeeze(0).squeeze(0).numpy()\n",
    "        output_img = (output_img * 0.5) + 0.5\n",
    "        output_img = np.clip(output_img, 0, 1)\n",
    "        output_pil = Image.fromarray((output_img * 255).astype(np.uint8))\n",
    "        output_pil.save(os.path.join(output_folder, filename))\n",
    "\n",
    "        # Compress encoded features\n",
    "        encoded_flat = encoded.cpu().detach().numpy().flatten()\n",
    "        encoded_flat = (encoded_flat * 255).astype(np.uint8)\n",
    "        encoded_list = list(encoded_flat)\n",
    "\n",
    "        code, low, high = arithmetic_compress(encoded_list)\n",
    "        compressed_size_bits = code.adjusted() + 1\n",
    "        compressed_size_bytes = compressed_size_bits / 8\n",
    "\n",
    "        print(f\"{filename} done\")\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        durations.append((filename, duration))\n",
    "        \n",
    "    csv_path = 'cae_arithmetic_durations.csv'\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Image Name', 'Duration (seconds)'])\n",
    "        writer.writerows(durations)\n",
    "    \n",
    "    print(f\"âœ… Duration tracking complete. Saved to: {csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc30f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = ECG_CAE().to(device)\n",
    "\n",
    "    if not os.path.exists(\"ecg_cae.pth\"):\n",
    "        data_dir = \"org_train\"\n",
    "        dataloader = get_dataloader(data_dir, batch_size=16, shuffle=True)\n",
    "        train_model(model, dataloader, device, num_epochs=40)\n",
    "\n",
    "    if os.path.exists(\"ecg_cae.pth\"):\n",
    "        model.load_state_dict(torch.load(\"ecg_cae.pth\", map_location=device))\n",
    "        print(\"Model loaded.\")\n",
    "\n",
    "    # Process the entire folder\n",
    "    process_folder(model, folder_path=\"org_ecg_10sec_resize\", device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
