{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b57ebf8-1ace-4a9d-91b7-b7edc712a7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Model loaded.\n",
      "🔍 Evaluating ecg_record_100.png...\n",
      "✅ Saved: cae\\ecg_record_100.png\n",
      "🔍 Evaluating ecg_record_101.png...\n",
      "✅ Saved: cae\\ecg_record_101.png\n",
      "🔍 Evaluating ecg_record_102.png...\n",
      "✅ Saved: cae\\ecg_record_102.png\n",
      "🔍 Evaluating ecg_record_103.png...\n",
      "✅ Saved: cae\\ecg_record_103.png\n",
      "🔍 Evaluating ecg_record_104.png...\n",
      "✅ Saved: cae\\ecg_record_104.png\n",
      "🔍 Evaluating ecg_record_105.png...\n",
      "✅ Saved: cae\\ecg_record_105.png\n",
      "🔍 Evaluating ecg_record_106.png...\n",
      "✅ Saved: cae\\ecg_record_106.png\n",
      "🔍 Evaluating ecg_record_107.png...\n",
      "✅ Saved: cae\\ecg_record_107.png\n",
      "🔍 Evaluating ecg_record_108.png...\n",
      "✅ Saved: cae\\ecg_record_108.png\n",
      "🔍 Evaluating ecg_record_109.png...\n",
      "✅ Saved: cae\\ecg_record_109.png\n",
      "🔍 Evaluating ecg_record_111.png...\n",
      "✅ Saved: cae\\ecg_record_111.png\n",
      "🔍 Evaluating ecg_record_112.png...\n",
      "✅ Saved: cae\\ecg_record_112.png\n",
      "🔍 Evaluating ecg_record_113.png...\n",
      "✅ Saved: cae\\ecg_record_113.png\n",
      "🔍 Evaluating ecg_record_114.png...\n",
      "✅ Saved: cae\\ecg_record_114.png\n",
      "🔍 Evaluating ecg_record_115.png...\n",
      "✅ Saved: cae\\ecg_record_115.png\n",
      "🔍 Evaluating ecg_record_116.png...\n",
      "✅ Saved: cae\\ecg_record_116.png\n",
      "🔍 Evaluating ecg_record_117.png...\n",
      "✅ Saved: cae\\ecg_record_117.png\n",
      "🔍 Evaluating ecg_record_118.png...\n",
      "✅ Saved: cae\\ecg_record_118.png\n",
      "🔍 Evaluating ecg_record_119.png...\n",
      "✅ Saved: cae\\ecg_record_119.png\n",
      "🔍 Evaluating ecg_record_121.png...\n",
      "✅ Saved: cae\\ecg_record_121.png\n",
      "🔍 Evaluating ecg_record_122.png...\n",
      "✅ Saved: cae\\ecg_record_122.png\n",
      "🔍 Evaluating ecg_record_123.png...\n",
      "✅ Saved: cae\\ecg_record_123.png\n",
      "🔍 Evaluating ecg_record_124.png...\n",
      "✅ Saved: cae\\ecg_record_124.png\n",
      "🔍 Evaluating ecg_record_200.png...\n",
      "✅ Saved: cae\\ecg_record_200.png\n",
      "🔍 Evaluating ecg_record_201.png...\n",
      "✅ Saved: cae\\ecg_record_201.png\n",
      "🔍 Evaluating ecg_record_202.png...\n",
      "✅ Saved: cae\\ecg_record_202.png\n",
      "🔍 Evaluating ecg_record_203.png...\n",
      "✅ Saved: cae\\ecg_record_203.png\n",
      "🔍 Evaluating ecg_record_205.png...\n",
      "✅ Saved: cae\\ecg_record_205.png\n",
      "🔍 Evaluating ecg_record_207.png...\n",
      "✅ Saved: cae\\ecg_record_207.png\n",
      "🔍 Evaluating ecg_record_208.png...\n",
      "✅ Saved: cae\\ecg_record_208.png\n",
      "🔍 Evaluating ecg_record_209.png...\n",
      "✅ Saved: cae\\ecg_record_209.png\n",
      "🔍 Evaluating ecg_record_210.png...\n",
      "✅ Saved: cae\\ecg_record_210.png\n",
      "🔍 Evaluating ecg_record_212.png...\n",
      "✅ Saved: cae\\ecg_record_212.png\n",
      "🔍 Evaluating ecg_record_213.png...\n",
      "✅ Saved: cae\\ecg_record_213.png\n",
      "🔍 Evaluating ecg_record_214.png...\n",
      "✅ Saved: cae\\ecg_record_214.png\n",
      "🔍 Evaluating ecg_record_215.png...\n",
      "✅ Saved: cae\\ecg_record_215.png\n",
      "🔍 Evaluating ecg_record_217.png...\n",
      "✅ Saved: cae\\ecg_record_217.png\n",
      "🔍 Evaluating ecg_record_219.png...\n",
      "✅ Saved: cae\\ecg_record_219.png\n",
      "🔍 Evaluating ecg_record_220.png...\n",
      "✅ Saved: cae\\ecg_record_220.png\n",
      "🔍 Evaluating ecg_record_221.png...\n",
      "✅ Saved: cae\\ecg_record_221.png\n",
      "🔍 Evaluating ecg_record_222.png...\n",
      "✅ Saved: cae\\ecg_record_222.png\n",
      "🔍 Evaluating ecg_record_223.png...\n",
      "✅ Saved: cae\\ecg_record_223.png\n",
      "🔍 Evaluating ecg_record_228.png...\n",
      "✅ Saved: cae\\ecg_record_228.png\n",
      "🔍 Evaluating ecg_record_230.png...\n",
      "✅ Saved: cae\\ecg_record_230.png\n",
      "🔍 Evaluating ecg_record_231.png...\n",
      "✅ Saved: cae\\ecg_record_231.png\n",
      "🔍 Evaluating ecg_record_232.png...\n",
      "✅ Saved: cae\\ecg_record_232.png\n",
      "🔍 Evaluating ecg_record_233.png...\n",
      "✅ Saved: cae\\ecg_record_233.png\n",
      "🔍 Evaluating ecg_record_234.png...\n",
      "✅ Saved: cae\\ecg_record_234.png\n",
      "✅ Durations saved to: cae_durations.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c01a90-9c11-4a98-9487-6676bddb9d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Convolutional Autoencoder\n",
    "class ECG_CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECG_CAE, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        _, _, h, w = x.size()\n",
    "        decoded = decoded[:, :, :h, :w]\n",
    "        return encoded, decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((296, 1024)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc36a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "def get_dataloader(data_dir, batch_size=16, shuffle=True):\n",
    "    dataset = ImageFolder(data_dir, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, pin_memory=True)\n",
    "\n",
    "# Train function\n",
    "def train_model(model, dataloader, device, num_epochs=10, lr=1e-3, save_path=\"ecg_cae.pth\"):\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for images, _ in dataloader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            _, outputs = model(images)\n",
    "            loss = criterion(outputs, images)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.6f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "# Evaluate single image and return duration\n",
    "def evaluate_image(model, image_path, device, save_dir=\"cae\"):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"L\")\n",
    "    resized = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        encoded, decoded = model(resized)\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    output_img = decoded.cpu().squeeze(0).squeeze(0).numpy()\n",
    "    output_img = (output_img * 0.5) + 0.5\n",
    "    output_img = np.clip(output_img, 0, 1)\n",
    "    output_pil = Image.fromarray((output_img * 255).astype(np.uint8))\n",
    "\n",
    "    # Save with same filename in \"cae\" folder\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = os.path.basename(image_path)\n",
    "    output_path = os.path.join(save_dir, filename)\n",
    "    output_pil.save(output_path)\n",
    "\n",
    "    print(f\"✅ Saved: {output_path}\")\n",
    "    return duration\n",
    "\n",
    "# Evaluate a folder of images and save durations to CSV\n",
    "def evaluate_folder(model, folder_path, device, output_csv='cae_durations.csv', save_dir=\"cae\"):\n",
    "    durations = []\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    for fname in image_files:\n",
    "        image_path = os.path.join(folder_path, fname)\n",
    "        print(f\"🔍 Evaluating {fname}...\")\n",
    "        duration = evaluate_image(model, image_path, device, save_dir)\n",
    "        durations.append((fname, duration))\n",
    "\n",
    "    # Save durations to CSV\n",
    "    with open(output_csv, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Image Name', 'Duration (seconds)'])\n",
    "        writer.writerows(durations)\n",
    "\n",
    "    print(f\"✅ Durations saved to: {output_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d38fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = ECG_CAE().to(device)\n",
    "\n",
    "    if not os.path.exists(\"ecg_cae.pth\"):\n",
    "        data_dir = \"org_train\"\n",
    "        dataloader = get_dataloader(data_dir, batch_size=16, shuffle=True)\n",
    "        train_model(model, dataloader, device, num_epochs=40)\n",
    "\n",
    "    if os.path.exists(\"ecg_cae.pth\"):\n",
    "        model.load_state_dict(torch.load(\"ecg_cae.pth\", map_location=device))\n",
    "        print(\"Model loaded.\")\n",
    "\n",
    "    # Evaluate images in folder and save durations\n",
    "    evaluate_folder(model, folder_path=\"org_ecg_10sec_resize\", device=device, output_csv=\"cae_durations.csv\", save_dir=\"cae\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
