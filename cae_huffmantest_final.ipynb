{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8802b8-7480-4357-b557-6f458cbc2a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ecg_record_100.png\n",
      "Processed ecg_record_101.png\n",
      "Processed ecg_record_102.png\n",
      "Processed ecg_record_103.png\n",
      "Processed ecg_record_104.png\n",
      "Processed ecg_record_105.png\n",
      "Processed ecg_record_106.png\n",
      "Processed ecg_record_107.png\n",
      "Processed ecg_record_108.png\n",
      "Processed ecg_record_109.png\n",
      "Processed ecg_record_111.png\n",
      "Processed ecg_record_112.png\n",
      "Processed ecg_record_113.png\n",
      "Processed ecg_record_114.png\n",
      "Processed ecg_record_115.png\n",
      "Processed ecg_record_116.png\n",
      "Processed ecg_record_117.png\n",
      "Processed ecg_record_118.png\n",
      "Processed ecg_record_119.png\n",
      "Processed ecg_record_121.png\n",
      "Processed ecg_record_122.png\n",
      "Processed ecg_record_123.png\n",
      "Processed ecg_record_124.png\n",
      "Processed ecg_record_200.png\n",
      "Processed ecg_record_201.png\n",
      "Processed ecg_record_202.png\n",
      "Processed ecg_record_203.png\n",
      "Processed ecg_record_205.png\n",
      "Processed ecg_record_207.png\n",
      "Processed ecg_record_208.png\n",
      "Processed ecg_record_209.png\n",
      "Processed ecg_record_210.png\n",
      "Processed ecg_record_212.png\n",
      "Processed ecg_record_213.png\n",
      "Processed ecg_record_214.png\n",
      "Processed ecg_record_215.png\n",
      "Processed ecg_record_217.png\n",
      "Processed ecg_record_219.png\n",
      "Processed ecg_record_220.png\n",
      "Processed ecg_record_221.png\n",
      "Processed ecg_record_222.png\n",
      "Processed ecg_record_223.png\n",
      "Processed ecg_record_228.png\n",
      "Processed ecg_record_230.png\n",
      "Processed ecg_record_231.png\n",
      "Processed ecg_record_232.png\n",
      "Processed ecg_record_233.png\n",
      "Processed ecg_record_234.png\n",
      "✅ Duration tracking complete. Saved to: cae_huffman.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import heapq\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f2951",
   "metadata": {},
   "source": [
    "CAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025012b0-dfa7-4632-9ea0-ed3850ee7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG_CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECG_CAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        _, _, h, w = x.size()\n",
    "        decoded = decoded[:, :, :h, :w]\n",
    "        return encoded, decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50d109",
   "metadata": {},
   "source": [
    "Huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48310c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class node:\n",
    "    def __init__(self, frequency, symbol, left=None, right=None):\n",
    "        self.frequency = frequency\n",
    "        self.symbol = symbol\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.huffman_direction = ''\n",
    "\n",
    "    def __lt__(self, nxt):\n",
    "        return self.frequency < nxt.frequency\n",
    "\n",
    "def get_frequency(bit_string):\n",
    "    freq = {}\n",
    "    for i in range(0, len(bit_string), 8):\n",
    "        byte = bit_string[i:i+8]\n",
    "        freq[byte] = freq.get(byte, 0) + 1\n",
    "    return freq\n",
    "\n",
    "def get_merged_huffman_tree(freq):\n",
    "    heap = [node(f, b) for b, f in freq.items()]\n",
    "    heapq.heapify(heap)\n",
    "    while len(heap) > 1:\n",
    "        left = heapq.heappop(heap)\n",
    "        right = heapq.heappop(heap)\n",
    "        left.huffman_direction = '0'\n",
    "        right.huffman_direction = '1'\n",
    "        merged = node(left.frequency + right.frequency, left.symbol + right.symbol, left, right)\n",
    "        heapq.heappush(heap, merged)\n",
    "    return heap[0]\n",
    "\n",
    "def calculate_huffman_codes(n, code='', codes={}):\n",
    "    code += n.huffman_direction\n",
    "    if n.left:\n",
    "        calculate_huffman_codes(n.left, code, codes)\n",
    "    if n.right:\n",
    "        calculate_huffman_codes(n.right, code, codes)\n",
    "    if not n.left and not n.right:\n",
    "        codes[n.symbol] = code\n",
    "    return codes\n",
    "\n",
    "def compress(bit_string):\n",
    "    freq = get_frequency(bit_string)\n",
    "    tree = get_merged_huffman_tree(freq)\n",
    "    codes = calculate_huffman_codes(tree)\n",
    "    compressed = ''.join(codes[bit_string[i:i+8]] for i in range(0, len(bit_string), 8))\n",
    "    return compressed, codes\n",
    "\n",
    "def decompress(compressed_string, codes):\n",
    "    reverse = {v: k for k, v in codes.items()}\n",
    "    current = \"\"\n",
    "    decompressed = \"\"\n",
    "    for bit in compressed_string:\n",
    "        current += bit\n",
    "        if current in reverse:\n",
    "            decompressed += reverse[current]\n",
    "            current = \"\"\n",
    "    return decompressed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((296, 1024)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "durations = []\n",
    "\n",
    "def compress_and_reconstruct_folder(model, input_folder, output_folder, device):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    def bin16_to_signed_int(b):\n",
    "        val = int(b, 2)\n",
    "        if val >= 2**15:\n",
    "            val -= 2**16\n",
    "        return val\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        start_time = time.time()\n",
    "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        image = Image.open(input_path).convert('L')\n",
    "        img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoded, _ = model(img_tensor)\n",
    "\n",
    "        encoded_np = encoded.cpu().numpy()\n",
    "        flat = np.round(encoded_np.flatten() * 1000).astype(np.int16)  # scale up to retain precision\n",
    "        bit_string = ''.join(format(val & 0xFFFF, '016b') for val in flat)\n",
    "\n",
    "        compressed_bits, codes = compress(bit_string)\n",
    "\n",
    "        # Decompression\n",
    "        decompressed_bits = decompress(compressed_bits, codes)\n",
    "        flat_vals = [bin16_to_signed_int(decompressed_bits[i:i+16]) for i in range(0, len(decompressed_bits), 16)]\n",
    "        reshaped = np.array(flat_vals, dtype=np.float32).reshape(encoded_np.shape) / 1000  # scale back down\n",
    "        reshaped_tensor = torch.tensor(reshaped).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            decoded = model.decoder(reshaped_tensor)\n",
    "\n",
    "        decoded = decoded[:, :, :img_tensor.size(2), :img_tensor.size(3)]  # Crop back\n",
    "        output_img = decoded.squeeze().cpu().numpy()\n",
    "        output_img = (output_img * 0.5) + 0.5  # De-normalize\n",
    "        output_img = np.clip(output_img, 0, 1)\n",
    "        output_img = (output_img * 255).astype(np.uint8)\n",
    "\n",
    "        save_path = os.path.join(output_folder, filename)\n",
    "        Image.fromarray(output_img).save(save_path)\n",
    "\n",
    "        print(f\"Processed {filename}\")\n",
    "\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        durations.append((filename, duration))\n",
    "\n",
    "    csv_path = 'cae_huffman.csv'\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Image Name', 'Duration (seconds)'])\n",
    "        writer.writerows(durations)\n",
    "    \n",
    "    print(f\"✅ Duration tracking complete. Saved to: {csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ECG_CAE().to(device)\n",
    "    model.load_state_dict(torch.load(\"ecg_cae.pth\", map_location=device))\n",
    "    model.eval()\n",
    "    compress_and_reconstruct_folder(model, \"org_ecg_10sec_resize\", \"caehuffman\", device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
